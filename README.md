## Research Scientist Guide
![Full Guide](https://img.shields.io/badge/AI-AI--guide-green) ![Version 1.0.0](https://img.shields.io/badge/Version-1.0.0-orange)

## Description
This guide will help me enhance my artificial intelligence skill set. I will follow two approaches to learning simultaneously: a Bottom-Up approach, where I focus on understanding mathematical concepts before applying them, and a Top-Down approach, which involves practical applications first, followed by theory. This preparation guide is specifically designed for my interview preparation.
#200daysofinterview-preparation. [7th March - 23rd Sept 2025]

**Algorithm ::** 

**Statistical-Analysis ::** [Statistics-Notes](https://kundan-kumarr.github.io/statistics-analysis/)

**Data-Science ::** https://kundan-kumarr.github.io/data-science/intro.html

**Data-Science Blog ::** https://kundan-kumarr.github.io/datascience-blog/

I think, this guide will be helpful who want to pursue in becoming Research Scientist.
Created 

-------------------------------------------------------------------------------- 
## Contents:
- [Data Structure and Algorithms](#Data-Structure-Algorithms)
- [Mathematical Foundation](#Mathematical-Foundations)
   - [Linear Algebra](#Linear-Algebra) 
   - [Probability](#Probability) 
   - [Calculus](#Calculus)
   - [Optimization Theory](#Optimization-Theory)
- [Machine Learning](#Machine-Learning)
- [Deep Learning](#Deep-Learning)
- [Reinforcement Learning](#Reinforcement-Learning)
- [Computer Vision](#Computer-Vision)
- [Graph Neural Network](#Graph-Neural-Network)
- [Federated Learning](#Federated-Learning)
- [Explainable AI](#Explainable-AI)
- [Robotics](#Robotics)
- [Parallelism](#Parallelism)
- [Natural Language Processing](#Natural-Language-Processing)
- [Statistical Analysis](#Statistical-Analysis)
    -  [Statistical Analysis with R](#Statistical-R)
    -  [Statistical Analysis with SAS](#Statistical-SAS)

-------------------------------------------------------------------------------- 
### Data Structure & Algorithms
##### Sorting
- Introduction to Sorting and Asymptotic Analysis
- Different Sorting Algorithms and their comparison
- Algorithm paradigms like Divide & Conquer, Decrease & Conquer, Transform & Conquer and Presorting
- Extensions of Merge Sort, Quick Sort, Heap Sort
- Common sorting-related coding interview problems

##### Recursion
- Recursion as a Lazy Manager's Strategy
- Recursive Mathematical Functions
- Combinatorial Enumeration
- Backtracking
- Exhaustive Enumeration & General Template
- Common recursion- and backtracking-related coding interview problems

##### Trees
- Dictionaries & Sets, Hash Tables 
- Modeling data as Binary Trees and Binary Search Tree and performing different operations over them
- Tree Traversals and Constructions 
- BFS Coding Patterns
- DFS Coding Patterns
- Tree Construction from its traversals 
- Common trees-related coding interview problems

##### Graphs
- Overview of Graphs
- Problem definition of the 7 Bridges of Konigsberg and its connection with Graph theory
- What is a graph, and when do you model a problem as a Graph?
- How to store a Graph in memory (Adjacency Lists, Adjacency Matrices, Adjacency Maps)
- Graphs traversal: BFS and DFS, BFS Tree, DFS stack-based implementation
- A general template to solve any problems modeled as Graphs
- Graphs in Interviews
- Common graphs-related coding interview problems

##### Dynamic Programming
- Dynamic Programming Introduction
- Modeling problems as recursive mathematical functions
- Detecting overlapping subproblems
- Top-down Memorization
- Bottom-up Tabulation
- Optimizing Bottom-up Tabulation
- Common DP-related coding interview problems

-------------------------------------------------------------------------------- 

### Mathematical Foundations:

Artificial Intelligence relies heavily on mathematical concepts and principles. To build a strong foundation in AI, one needs to have a solid understanding of various mathematical disciplines such as machine learning, deep learning, computer vision, reinforcement learning, and more. These areas form the backbone of AI and are essential for developing intelligent systems that can learn, reason, and make decisions based on data. Therefore, proficiency in math is crucial for those pursuing a career in AI.

Artificial Intelligence are heavily on mathematics. This fondation path will consists maths part Machine learning,Deep Learning,Computer Vision,Reinforcement learning and so on.

The Mathematical Foundation part is for all Artificial Intelligence branches such as Machine Learning, Reinforcement Learning, Computer Vision and so on. AI is heavily math-theory based so a solid foundation is essential.

### Linear Algebra 

<details>
  <summary>:infinity:</summary>
  
<!--START_SECTION:activity-->  

  This branch of Math is crucial for understanding the mechanism of Neural Networks which are the norm for NLP methodologies in nowadays State-of-The-Art.

Resource                    | Difficulty     | Relevance 
------------------------- | --------------- | -------------------------------
[MIT Gilbert Strang 2005 Linear Algebra ğŸ¥][gilbertStrang] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span><span>â˜†</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning) ![50%](https://progress-bar.dev/50/?title=Machine+Learning+Algorithms&color=000000) ![75%](https://progress-bar.dev/75/?title=Computer+Vision&color=ff0101)
[Linear Algebra 4th Edition by Friedberg ğŸ“˜][Friedberg] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[Mathematics for Machine Learning Book: Chapter 2 ğŸ“˜][mmlbook] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>| ![50%](https://progress-bar.dev/50/?title=Deep+Learning) ![75%](https://progress-bar.dev/75/?title=Machine+Learning+Algorithms&color=000000)
[James Hamblin Awesome Lecture Series ğŸ¥][James_Hamblin] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[3Blue1Brown Essence of Linear Algebra ğŸ¥][3blue] | <div class="star-ratings-top"><span>â˜…</span><span>â˜†</span><span>â˜†</span><span>â˜†</span><span>â˜†</span></div>| ![25%](https://progress-bar.dev/25/?title=Machine+Learning+Algorithms&color=000000) ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[Mathematics For Machine Learning Specialization: Linear Algebra ğŸ¥][MMLLA] | <div class="star-ratings-top"><span>â˜…</span><span>â˜†</span><span>â˜†</span><span>â˜†</span><span>â˜†</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine-Learning-Algorithms&color=000000) ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[Matrix Methods for Linear Algebra for Gilber Strang UPDATED! ğŸ¥][matrixmethods] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>|  ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
  <!--END_SECTION:activity-->

</details>

### Probability

<details>
  <summary>:atom: </summary>
  
<!--START_SECTION:activity-->  

Most of Natural Language Processing and Machine Learning Algorithms are based on Probability theory. So this branch is extremely important for grasping how old methods work.
Resource                    | Difficulty     | Relevance 
------------------------- | --------------- | -------------------------------
[Joe Blitzstein Harvard Probability and Statistics Course ğŸ¥][harvard] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine+Learning+Algorithms&color=000000) ![25%](https://progress-bar.dev/25/?title=Deep+Learning) ![100%](https://progress-bar.dev/100/?title=Natural+Language+Processing&color=ff69b4) 
[MIT Probability Course 2011 Lecture videos ğŸ¥][mitprob11] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine+Learning+Algorithms&color=000000) ![75%](https://progress-bar.dev/75/?title=Natural+Language+Processing&color=ff69b4) 
[MIT Probability Course 2018 short videos UPDATED! ğŸ¥][mitprob18] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†<span>â˜†</span></div>| ![25%](https://progress-bar.dev/50/?title=Machine+Learning+Algorithms&color=000000) ![25%](https://progress-bar.dev/25/?title=Deep+Learning) ![100%](https://progress-bar.dev/100/?title=Natural+Language+Processing&color=ff69b4) 
[Mathematics for Machine Learning Book: Chapter 6 ğŸ“˜][mmlbook] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>| ![75%](https://progress-bar.dev/75/?title=Machine+Learning+Algorithms&color=000000) ![25%](https://progress-bar.dev/25/?title=Deep+Learning) ![75%](https://progress-bar.dev/75/?title=Natural+Language+Processing&color=ff69b4) 
 [Probalistic Graphical Models CMU Advanced ğŸ¥][cmuprob] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine+Learning+Algorithms&color=000000) ![25%](https://progress-bar.dev/25/?title=Deep+Learning) ![100%](https://progress-bar.dev/100/?title=Natural+Language+Processing&color=ff69b4) 
[Probalistic Graphical Models Stanford Daphne Advanced ğŸ¥][stanfordprobgraph] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine+Learning+Algorithms&color=000000) ![25%](https://progress-bar.dev/25/?title=Deep+Learning) ![25%](https://progress-bar.dev/25/?title=Natural+Language+Processing&color=ff69b4) 
 [A First Course In Probability Book by Ross ğŸ“˜][probBook] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine-Learning-Algorithms&color=000000) 
 [Joe Blitzstein Harvard Professor Probability Awesome Book ğŸ“˜][harvBook] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>| ![50%](https://progress-bar.dev/50/?title=Machine-Learning-Algorithms&color=000000) 
  <!--END_SECTION:activity-->

</details>

[harvBook]: https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view

### Calculus

<details>
  <summary>:triangular_ruler:</summary>
  


<!--START_SECTION:activity--> 
Resource                    | Difficulty     | Relevance 
------------------------- | --------------- | --------------------------
[Essence of Calculus by 3Blue1BrownğŸ¥][bluecal]| <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span><span>â˜†</span></div>|![75%](https://progress-bar.dev/75/?title=Deep+Learning)
[Single Variable Calculus MIT 2007ğŸ¥][single07]| <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span></div>|![75%](https://progress-bar.dev/75/?title=Deep+Learning)
[Strang's Overview of CalculusğŸ¥][strangcalc]|<div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[MultiVariable Calculus MIT 2007ğŸ¥][multi07]| <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[Princeton University Multivariable Calculus 2013ğŸ¥][princeton]|<div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning)
[Calculus Book by Stewart ğŸ“˜][calcbok]|<div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning) ![25%](https://progress-bar.dev/50/?title=Machine-Learning-Algorithms&color=000000) 
[Mathematics for Machine Learning Book: Chapter 5 ğŸ“˜][mmlbook] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜†</span><span>â˜†</span></div>| ![75%](https://progress-bar.dev/75/?title=Deep+Learning) ![50%](https://progress-bar.dev/50/?title=Machine-Learning-Algorithms&color=000000) 


 <!--END_SECTION:activity-->

</details>

 ### Optimization Theory
 
<details>
  <summary> ğŸ“‰ </summary>
  

<!--START_SECTION:activity--> 
-Resource                    | Difficulty     | Relevance 
------------------------- | --------------- | --------------------------
[CMU optimization course 2018ğŸ¥][cmuopti]| <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning) ![25%](https://progress-bar.dev/25/?title=Machine-Learning-Algorithms&color=000000) 
[CMU Advanced optimization courseğŸ¥][cmuadvopti]| <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning) 
[Stanford Famous optimization course ğŸ¥][stanfordopti]| <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning) 
[Boyd Convex Optimization Book ğŸ“•][boyd] | <div class="star-ratings-top"><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span><span>â˜…</span></div>| ![100%](https://progress-bar.dev/100/?title=Deep+Learning) 
 <!--END_SECTION:activity-->

</details>

-------------------------------------------------------------------------------- 

## Machine Learning

Considered a fancy name for Statistical models where its main goal is to learn from data for several usages. It is considered highly recommended to master these statistical techniques before Research as most of research is inspired by most of the Algorithms.

Resource                    | Difficulty Level 
------------------------- | ---------------
[Mathematics for Machine Learning Part 2 ğŸ“š][fullmmlbook] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Pattern Recognition and Machine LeanringğŸ“š][patternML]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Elements of Statistical Learning ğŸ“š][eesl]|![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Introduction to Statistical Learning  ğŸ“š][introSL]|![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg) 
[Machine Learning: A Probalisitic Perspective ğŸ“š][murphyml]|![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Berkley CS188 Introduction to AI course ğŸ¥][cs188]|![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg) 
[MIT Classic AI course taught by Prof. Patrick H. Winston ğŸ¥][mitai]|![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg) 
[Stanford AI course 2018 ğŸ¥][stai18]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[California Instuite of Technology Learning from Data course ğŸ¥][caltldc]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[CMU Machine Learning 2015 10-601 ğŸ¥][cmuml2015]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[CMU Statistical Machine Learning 10-702 ğŸ¥][cmu702]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Information Theory, Pattern Recognition ML course 2012 ğŸ¥][PR2012]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Large Scale Machine Learning Toronto University 2015 ğŸ¥][toronto2015]|![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Algorithmic Aspects of Machine Learning MIT ğŸ¥][Mitaspects]|![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[MIT Course 9.520 - Statistical Learning Theory and Applications, Fall 2015 ğŸ¥][mitfallslt]|![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Undergraduate Machine Learning Course University of British Columbia 2013 ğŸ¥][ubc2013]|![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg) 


-------------------------------------------------------------------------------- 

[murphyml]: http://noiselab.ucsd.edu/ECE228/Murphy_Machine_Learning.pdf
[introSL]: https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf
[patternML]:http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf
[eesl]: https://web.stanford.edu/~hastie/Papers/ESLII.pdf
[fullmmlbook]: https://mml-book.com/
[ubc2013]:https://www.youtube.com/watch?v=w2OtwL5T1ow&list=PLE6Wd9FR--EdyJ5lbFl8UuGjecvVw66F6
[mitfallslt]: https://www.youtube.com/playlist?list=PLyGKBDfnk-iDj3FBd0Avr_dLbrU8VG73O
[Mitaspects]: https://www.youtube.com/playlist?list=PLB3sDpSRdrOvI1hYXNsa6Lety7K8FhPpx
[toronto2015]:https://video-archive.fields.utoronto.ca/view/2800
[PR2012]: http://videolectures.net/course_information_theory_pattern_recognition/
[cmu702]: https://www.youtube.com/playlist?list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r
[cmuml2015]: http://www.cs.cmu.edu/~ninamf/courses/601sp15/lectures.shtml
[caltldc]: https://work.caltech.edu/lectures.html
[cs188]: https://inst.eecs.berkeley.edu/~cs188/fa18/
[mitai]: https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/lecture-1-introduction-and-scope/
[stai18]: https://www.youtube.com/playlist?list=PLoROMvodv4rO1NB9TD4iUZ3qghGEGtqNX

## Deep Learning 

One of the major breakthroughs in the field of intersection between Artificial Intelligence and Computer Science. It lead to countless advances in technology and considered the standard way to do Artificial Intelligence.

Resource                    | Difficulty Level 
------------------------- | ---------------
[Deep Learning Book by Ian Goodfellow ğŸ“š][Ian] |![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[UCL Deepmind Deep Learning ğŸ¥][ucl2020] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Advanced Talks by Deep Learning Pioneers ğŸ¥][talkie] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Stanford Autumn 2018 Deep Learning Lectures ğŸ¥][18standeep] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[FAU Deep Learning 2020 Series ğŸ¥][fau] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg) 
[CMU Deep Learning course 2020 ğŸ¥][cmudeep] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg) 
[Stanford Convolutional Neural Network 2017 ğŸ¥][stanfcnn] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Oxford Deep Learning Awesome Lectures 2015 ğŸ¥][oxforddeep] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Stanford NLP with Deep Learning 2019 ğŸ¥][stanfordnlp2019] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Deep Learning from Probability and Statistics POV ğŸ¥][alideep] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[Advanced Deep Learning UCL 2017 course + Reinforcement Learning ğŸ¥][ucladvrein] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Deep Learning UC Berkley 2020 Course ğŸ¥][berkley2020] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[NYU Deep Learning with Pytorch hands on ğŸ¥][DeepPy] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Classic Jeoffrey Hinton Old course OUTDATED ğŸ¥][jeoff] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Pieter Abdeel Deep Unsupervised Learning ğŸ¥][abdeeladv] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Hugo Larochelle Deep Learning series ğŸ¥][hugodeep] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[Deep Learning Book Explanation Series ğŸ¥][deepbookexp] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Deep Learning Introduction by Durham University ğŸ¥][Durham] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[Fast.ai Practical Deep Learning ğŸ¥][fast1] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[Fast.ai Deep Learning From Foundations ğŸ¥][fast2] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[Deep Learning with Python (Keras Author) ğŸ“š][keras] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
--------------------------------------------------------------------------------  

## Reinforcement Learning 

It is a sub-field of AI which focuses on learning by observation/rewards. 

Resource                    | Difficulty Level 
------------------------- | ---------------
[Introduction to Reinforcement Learning ğŸ“š][rlbook] | ![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[David Silver Deep Mind Introductory Lectures ğŸ¥][dsIntrodu] | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[Stanford 2018 cs234 Reinforcement LearningğŸ¥ ][cs234] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Stanford 2019 cs330 Meta Learning advanced course ğŸ¥][cs330] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Sergie Levine 2018 UC Berkley Lecture Videos ğŸ¥][ucb2018rl] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Waterloo cs885 Reinforcement Learing ğŸ¥][cs885] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Sergie Levine 2020 Deep Reinforcement Learning ğŸ¥][sergie2020rl] | ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Reinforcement Learning Specialization Coursea GOLDEN coursesğŸ¥ (Though it is not free but you can apply for financial aid)][courseraRL] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)

--------------------------------------------------------------------------------  

## Natural Language Processing

It is a sub-field of AI which focuses on the interpretation of Human Language. 

Resource                    | Difficulty Level 
------------------------- | ---------------
[Jurafsky Speech and Language Processing ğŸ“š][jurafskybook]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Christopher Manning Foundations of Statistical NLPğŸ“š][fsnlp]| ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[Christopher Manning Introduction to Information RetrievalğŸ“š][manninginformationr]| ![Advanced](https://img.shields.io/badge/Level-Advanced-red.svg)
[cs224n Natural Language Processing with Deep Learning GOLDEN 2019ğŸ¥][stanfordnlp2019] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Oxford Natural Language Processing with Deep Learning 2017ğŸ¥][oxfordnlp] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Michigan Introduction to NLPğŸ¥][michigannlp]  | ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)
[cs224u Natural Language Understanding 2019 ğŸ¥][stanfordnlu] |![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[cmu 2021 Neural Nets for NLP 2021ğŸ¥][cmunlp2021]|![Intermediate](https://img.shields.io/badge/Level-Intermediate-yellow.svg)
[Jurafsky and Manning Introduction to Natural Language ProcessingğŸ¥][jurafskynlp]| ![Introductory](https://img.shields.io/badge/Level-Introductory-brightgreen.svg)

### Must Read NLP Papers:
In this section, I am going to list the most influential papers that help people who want to dig deeper into the research world of NLP to catch up.
Paper                    | Comment
------------------------- | ---------------
# TODO









[manninginformationr]: https://nlp.stanford.edu/IR-book/pdf/irbookprint.pdf
[fsnlp]: https://github.com/shivamms/books/blob/master/nlp/Foundations%20of%20Statistical%20Natural%20Language%20Processing%20-%20Christopher%20D.%20Manning.pdf
[jurafskybook]: https://web.stanford.edu/~jurafsky/slp3/
[jurafskynlp]: https://www.youtube.com/watch?v=zQ6gzQ5YZ8o&list=PLoROMvodv4rOFZnDyrlW3-nI7tMLtmiJZ
[cmunlp2021]: https://www.youtube.com/watch?v=vnx6M7N-ggs&list=PL8PYTP1V4I8AkaHEJ7lOOrlex-pcxS-XV
[stanfordnlu]: https://www.youtube.com/watch?v=tZ_Jrc_nRJY&list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20
[michigannlp]:https://www.youtube.com/watch?v=n25JjoixM3I&list=PLLssT5z_DsK8BdawOVCCaTCO99Ya58ryR 
[oxfordnlp]: https://www.youtube.com/watch?v=RP3tZFcC2e8&list=PL613dYIGMXoZBtZhbyiBqb0QtgK6oJbpm
[courseraRL]: https://www.coursera.org/specializations/reinforcement-learning
[sergie2020rl]: https://www.youtube.com/watch?v=JHrlF10v2Og&list=PL_iWQOsE6TfURIIhCrlt-wj9ByIVpbfGc
[cs885]: https://www.youtube.com/playlist?list=PLdAoL1zKcqTXFJniO3Tqqn6xMBBL07EDc
[ucb2018rl]: https://www.youtube.com/watch?v=ue9aS17d5iI&list=PLkFD6_40KJIxJMR-j5A1mkxK26gh_qg37&index=2
[cs330]: https://www.youtube.com/watch?v=0rZtSwNOTQo&list=PLoROMvodv4rMC6zfYmnD7UG3LVvwaITY5
[cs234]: https://www.youtube.com/playlist?list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u
[dsIntrodu]: https://www.youtube.com/watch?v=2pWv7GOvuf0&list=PLqYmG7hTraZDM-OYHWgPebj2MfCFzFObQ
[rlbook]: http://incompleteideas.net/book/RLbook2020.pdf
[Ian]: https://github.com/janishar/mit-deep-learning-book-pdf/blob/master/complete-book-pdf/Ian%20Goodfellow%2C%20Yoshua%20Bengio%2C%20Aaron%20Courville%20-%20Deep%20Learning%20(2017%2C%20MIT).pdf
[fast2]: https://course19.fast.ai/part2
[fast1]: https://course.fast.ai/
[abdeeladv]: https://www.youtube.com/watch?v=V9Roouqfu-M&list=PLwRJQ4m4UJjPiJP3691u-qWwPGVKzSlNP
[durham]: https://www.youtube.com/watch?v=s2uXPz3wyCk&list=PLMsTLcO6etti_SObSLvk9ZNvoS_0yia57
[deepbookexp]: https://www.youtube.com/watch?v=vi7lACKOUao&list=PLsXu9MHQGs8df5A4PzQGw-kfviylC-R9b
[hugodeep]: https://www.youtube.com/watch?v=SGZ6BttHMPw&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH
[jeoff]: https://www.youtube.com/watch?v=cbeTc-Urqak&list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9
[DeepPy]: https://www.youtube.com/watch?v=0bMe_vCZo30&list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq
[berkley2020]: https://www.youtube.com/watch?v=Va8WWRfw7Og&list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW
[ucladvrein]: https://www.youtube.com/watch?v=iOh7QUZGyiU&list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs
[alideep]: https://www.youtube.com/watch?v=fyAZszlPphs&list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE
[stanfordnlp2019]: https://www.youtube.com/watch?v=8rXD5-xhemo&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z
[oxforddeep]: https://www.youtube.com/watch?v=PlhFWT7vAEw&list=RDQMa66mIb9tImc&start_radio=1
[stanfcnn]: https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv
[cmudeep]: https://www.youtube.com/watch?v=0Oqpax2Q2hc&list=PLp-0K3kfddPzCnS4CqKphh-zT3aDwybDe
[fau]: https://www.youtube.com/watch?v=p-_Stl0t3kU&list=PLpOGQvPCDQzvgpD3S0vTy7bJe2pf_yJFj
[18standeep]: https://www.youtube.com/watch?v=PySo_6S4ZAg&list=PLoROMvodv4rOABXSygHTsbvUz4G_YQhOb
[talkie]: https://www.youtube.com/watch?v=vFYkyk_GmWM&list=PLhb1t0L7sKy2q7on_7dpgOACs3qpNbfkR&index=2
[ucl2020]: https://www.youtube.com/watch?v=7R52wiUgxZI&list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF
[boyd]: https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf
[cmuopti]: https://www.youtube.com/watch?v=Di9f47LAzHQ&list=PLRPU00LaonXQ27RBcq6jFJnyIbGw5azOI
[cmuadvopti]: https://www.youtube.com/watch?v=yBO4E1FARaA&list=PLjTcdlvIS6cjdA8WVXNIk56X_SjICxt0d
[stanfordopti]: https://www.youtube.com/watch?v=McLq1hEq3UY&list=PL3940DD956CDF0622
[calcbok]: http://index-of.co.uk/Mathematics/Calculus%20-%20J.%20Stewart.pdf
[princeton]: https://www.youtube.com/watch?v=uDByROsGzuk&list=PLGqzsq0erqU7h6_bpE-CgJp4iX5aRju28
[multi07]: https://www.youtube.com/watch?v=PxCxlsl_YwY&list=PL4C4C8A7D06566F38
[strangcalc]: https://www.youtube.com/watch?v=X9t-u87df3o&list=PLBE9407EA64E2C318
[single07]: https://www.youtube.com/watch?v=7K1sB05pE0A&list=PL590CCC2BC5AF3BC1
[matrixmethods]: https://www.youtube.com/watch?v=Cx5Z-OslNWE&list=PLUl4u3cNGP63oMNUHXqIUcrkS2PivhN3k
[bluecal]: https://www.youtube.com/watch?v=WUvTyaaNkzM&list=PL0-GT3co4r2wlh6UHTUeQsrf3mlS2lk6x
[probBook]: http://www.seyedkalali.com/wp-content/uploads/2016/11/A-First-Course-in-Probability-8th-ed.-Sheldon-Ross.pdf
[stanfordprobgraph]: https://www.youtube.com/watch?v=GqMzbbaN6T4&list=PLzERW_Obpmv-_TkPEmCyzaJUGHtl7S01i
[cmuprob]: https://www.youtube.com/watch?v=oqvdH_8lmCA&list=PLoZgVqqHOumTqxIhcdcpOAJOOimrRCGZn
[mitprob18]: https://www.youtube.com/watch?v=1uW3qMFA9Ho&list=PLUl4u3cNGP60hI9ATjSFgLZpbNJ7myAg6
[mitprob11]: https://www.youtube.com/watch?v=j9WZyLZCBzs&list=PLUl4u3cNGP61MdtwGTqZA0MreSaDybji8
[harvard]: https://www.youtube.com/watch?v=KbB0FjPg0mw&list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo
[MMLLA]: https://www.youtube.com/watch?v=T73ldK46JqE&list=PLiiljHvN6z1_o1ztXTKWPrShrMrBLo5P3
[3blue]: https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab
[gilbertStrang]: https://www.youtube.com/watch?v=QVKj3LADCnA&list=PL49CF3715CB9EF31D
[Friedberg]: https://npqke7p41z.pdcdn2.xyz/dl2.php?id=187502855&h=fe4fe4abfa10c9c6a51456cdff771ba1&u=cache&ext=pdf&n=Linear%20algebra%204th%20edition
[mmlbook]: https://mml-book.github.io/book/mml-book.pdf
[James_Hamblin]: https://www.youtube.com/watch?v=HAoL5fPmgrw&list=PLNr8B4XHL5kGDHOrU4IeI6QNuZHur4F86
[keras]: https://www.manning.com/books/deep-learning-with-python



Here is a 5-phase (8-month) roadmap to transition to AI/ML"- Sorry there are no shortcuts

Stepping into ML can be difficult, but a clear roadmap can make all the difference. The only resource you need: Vizuaraâ€™s YouTube playlists.

Phase 1ï¸âƒ£: Mathematical Foundations (20-25 hours)
Playlist 1: Foundations for ML: https://lnkd.in/gKz-eybU
-Why Begin Here: Grasp the basics- Linear algebra, Probability, Statistics, Calculus, Optimization, Programming fundamentals
-Commitment: 2-3 hours weekly for 8 weeks.

Phase 2ï¸âƒ£: Machine Learning (60-65 hours)
ğŸ“ŒPlaylist 1: ML Teach by Doing: https://lnkd.in/gn2dEcE2
-Why Itâ€™s Important: Practical, project-based learning to understand ML workflows.
-Commitment: 4 hours weekly for 10 weeks.

ğŸ“ŒPlaylist 2: Decision Trees from Scratch: https://lnkd.in/g3cmj2BR
-Why Itâ€™s Useful: Master decision tree algorithms are the backbone of many ML models.
-Commitment: 4 hours weekly for 5 weeks.

Phase 3ï¸âƒ£: Deep Learning (35-40 hours)
ğŸ“ŒPlaylist 1: Neural Networks from Scratch: https://lnkd.in/gj8kHe2T
-Why It Matters: Understand the mechanics of neural networks through implementation.
-Commitment: 5 hours weekly for 8 weeks.

Phase 4ï¸âƒ£: Advanced topics: Graph Neural Networks (40-45 hours)
ğŸ“ŒPlaylist 1: Graph Neural Networks - Theory, Applications and Research: https://lnkd.in/g3RCPS8e
-Why Learn This: Graph-based ML is becoming increasingly relevant in fields like social networks and biology.
-Commitment: 3 hours weekly for 8 weeks.

ğŸ“ŒPlaylist 2: ML Project-Based Course: Explainable AI: https://lnkd.in/gNEx3ghr
Why XAI?: Build ML projects with a focus on interpretability
-Commitment: 3 hours weekly for 5 weeks.
-Outcome: Publish your first research paper using XAI techniques.

Phase 5ï¸âƒ£: Generative AI, Transformers, and LLMs (100-110 hours)
ğŸ“ŒPlaylist 1: GenAI for Beginners (8 hours): https://lnkd.in/gUgXxVzh
ğŸ“ŒPlaylist 2: LLMs from scratch (40-45 hours): https://lnkd.in/gjcyfCcE
ğŸ“ŒPlaylist 3: Hands-on LLMs (40-45 hours): https://lnkd.in/gJQ7ryE4
ğŸ“ŒPlaylist 4: Transformers (15 hours): https://lnkd.in/g_3Qdu6d
-Why These Topics?: Learning about LLMs, transformers, and generative AI will make you future-ready.
-Commitment: 5 hours weekly for 20 weeks.

ğŸ”¸Optional [140 hours]
ğŸ“ŒIntroduction to Machine Learning in Julia [40 hours]: https://lnkd.in/g8A3DtQW
ğŸ“ŒZero to Hero in Data Science [40 hours]: https://lnkd.in/gNEgx2Cz
ğŸ“ŒHands-on PINN [20 hours]: https://lnkd.in/gta5hgHZ
ğŸ“ŒML in Hindi [40 hours]: https://lnkd.in/giD88GzZ

***
âœ…Total Duration: 275 hours + optional 140 hours
âœ…Timeline: 6-8 months, balancing learning with practical application.
âœ…Outcome: Build foundational ML knowledge, gain practical skills, and stay ahead with advanced topics.

***
If you are willing to spend time, this roadmap will help you get there. 

Follow Vizuaraâ€™s YouTube channel for structured and beginner-friendly playlists: https://lnkd.in/g455AJVw

Your ML journey begins nowâ€”start building your expertise today.


[//]: # (These are reference links used in the body of this note and get stripped out when the markdown processor does its job. There is no need to format nicely because it shouldn't be seen. Thanks SO - http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax)

   [dill]: <https://github.com/joemccann/dillinger>
   [git-repo-url]: <https://github.com/joemccann/dillinger.git>
   [john gruber]: <http://daringfireball.net>
   [df1]: <http://daringfireball.net/projects/markdown/>
   [markdown-it]: <https://github.com/markdown-it/markdown-it>
   [Ace Editor]: <http://ace.ajax.org>
   [node.js]: <http://nodejs.org>
   [Twitter Bootstrap]: <http://twitter.github.com/bootstrap/>
   [jQuery]: <http://jquery.com>
   [@tjholowaychuk]: <http://twitter.com/tjholowaychuk>
   [express]: <http://expressjs.com>
   [AngularJS]: <http://angularjs.org>
   [Gulp]: <http://gulpjs.com>

   [PlDb]: <https://github.com/joemccann/dillinger/tree/master/plugins/dropbox/README.md>
   [PlGh]: <https://github.com/joemccann/dillinger/tree/master/plugins/github/README.md>
   [PlGd]: <https://github.com/joemccann/dillinger/tree/master/plugins/googledrive/README.md>
   [PlOd]: <https://github.com/joemccann/dillinger/tree/master/plugins/onedrive/README.md>
   [PlMe]: <https://github.com/joemccann/dillinger/tree/master/plugins/medium/README.md>
   [PlGa]: <https://github.com/RahulHP/dillinger/blob/master/plugins/googleanalytics/README.md>
